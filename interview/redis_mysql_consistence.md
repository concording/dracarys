
如果要“保证”数据的安全性，那么会带来开销的进一步提升，以至于使用redis带来的性能优势都会丧失。正确的做法是区分不同的业务，使得并不需要“保证”数据一致性的场合，可以使用redis优化。而敏感的场合依然使用mysql。


### 读Redis，写MySQL，同时消费MySQL binlog更新Redis。

说个大概吧，我们热数据基本都是redis，增删改都是操作mysql，对于读是保存到redis，这样就涉及到数据同步操作，同步操作分为两大块，我们的叫法是，一个是全量(将全部数据一次写入到redis，时间几小时不等)，一个是增量（实时更新）。这里说的是增量，主要问题是即时性，因为增删改都是直接操作mysql变更都在MySQL（这里高并发的问题是用分库分表加外层的负载均衡） 所以我们的方向是读取binlog然后分析 ，利用消息推送到某服务器A，再进行分析，然后更新各台redis，消息推送工具用的是rabbitMQ，可设定某表的变更推送(分三类update insert delate 包含变更前后的数据)，这里有个问题是：mysql数据操作太频繁产生的推送可能会很多，所以分析处理脚本处理速度一定要跟得上（我用Python写，前期多线程（坑），后来改成多进程），还有一个问题是，对于mysql-redis的数据关系映射设定不要太复杂，一表对一表就行，数据组合交给业务层做，这样分析处理脚本不会太多负担，处理速度更快，而且操作redis也更简单，redis每个对应mysql数据表的可使用多端口多实例，redis是单线程而且这样对于redis的主从和负载均衡有利，

题外话：对于服务器A 可以再给其它服务做一个数据表增量变更数据获取接口，利用数据纬度，获取时间段的变更数据。

追加，对于订单类部分，都是完全使用mysql，这个做好数据服务器，DB，table，分区，的拆分就好了，看并发请求越多拆分越多。

上面说太多都是屁话，其实就是MySQL binlog增量订阅消费+消息队列+处理并把数据更新到redis

一个简单的例子。
[https://github.com/liukelin/canal_mysql_nosql_sync](https://link.zhihu.com/?target=https%3A//github.com/liukelin/canal_mysql_nosql_sync)


